{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# models/classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for pre-processing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# tools for classifier evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# tools for hyper-parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tools for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for nan values checking\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"GaussianNB\" : GaussianNB(),\n",
    "    \"DecisionTreeClassifier\" : DecisionTreeClassifier(max_depth=None, min_samples_leaf=2, random_state=42),\n",
    "    \"SVC\" : SVC(C=10, kernel=\"poly\", random_state=42),\n",
    "    \"KNeighbours\": KNeighborsClassifier(n_neighbors=3, weights=\"distance\"),\n",
    "    \"LogisticRegression\": LogisticRegression(penalty=\"none\", random_state=42)\n",
    "}\n",
    "\n",
    "tuned_models = {\n",
    "            \"GaussianNB\": GaussianNB(),\n",
    "            \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "            \"SVC\" : SVC(),\n",
    "            \"KNeighbours\": KNeighborsClassifier(),\n",
    "            \"LogisticRegression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "hyper_params = {\n",
    "    \"DecisionTreeClassifier\" : [\"max_depth\", \"min_samples_leaf\"],\n",
    "    \"SVC\" : [\"C\", \"kernel\"],\n",
    "    \"KNeighbours\": [\"weights\", \"n_neighbors\"],\n",
    "    \"LogisticRegression\": [\"C\", \"penalty\"]\n",
    "}\n",
    "\n",
    "normal_scores_8x8 = np.arange(5)\n",
    "tuned_scores_8x8 = np.arange(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2996, in run_cell_async\n",
      "    self.history_manager.store_inputs(self.execution_count,\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\history.py\", line 719, in store_inputs\n",
      "    with self.db_input_cache_lock:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Dimitar\\anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "mnist_28x28_train = np.load(\"mnist_28x28_train.npy\")\n",
    "mnist_8x8_train = np.load(\"mnist_8x8_train.npy\")\n",
    "train_labels = np.load(\"train_labels.npy\")\n",
    "\n",
    "mnist_28x28_test = np.load(\"mnist_28x28_test.npy\")\n",
    "mnist_8x8_test = np.load(\"mnist_8x8_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(scores, bar_1, bar_2):\n",
    "    \n",
    "    scores_1 = scores[0]\n",
    "    scores_2 = None\n",
    "    \n",
    "    if len(scores) == 2:\n",
    "        scores_2 = scores[1]\n",
    "   \n",
    "    \n",
    "    labels = ['NB', 'Tree', 'SVC', 'K-NN', 'LR']\n",
    "        \n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    width = 0.35\n",
    "    rects1 = ax.bar(x - width/2, scores_1, width, label=bar_1)\n",
    "    rects2 = ax.bar(x + width/2, scores_2, width, label=bar_2)\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('Scores by algorithm and dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def setModelParams(target, source):\n",
    "    for name, value in source.get_params().items():\n",
    "        target.get_params()[name] = value\n",
    "        \n",
    "\n",
    "setModelParams(LogisticRegression(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Hint: `plt.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Size</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mnist_8x8</td>\n",
       "      <td>3750</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnist_28x28</td>\n",
       "      <td>3750</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset  Size  Features\n",
       "0    mnist_8x8  3750        64\n",
       "1  mnist_28x28  3750       784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Digit</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Digit  Frequency\n",
       "0    0.0      395.0\n",
       "1    1.0      376.0\n",
       "2    2.0      367.0\n",
       "3    3.0      378.0\n",
       "4    4.0      388.0\n",
       "5    5.0      366.0\n",
       "6    6.0      371.0\n",
       "7    7.0      366.0\n",
       "8    8.0      366.0\n",
       "9    9.0      377.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Picture number 0 in the train sets is of class:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFirst images from the datasets are 1s. We can see the two images differ\\nin the amount of information they provide because of the difference in dimensionality.\\n\\nThe digits in the dataset are not uniformly distributed, because 0 is predominant, \\nwhile 5 and 7 are least frequent.\\n\\nBecause the data in the second dataset contains more correlation and more redundant information\\nthe resulting presumption is that the smaller dataset will on average perform better.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_sizes = pd.DataFrame([\n",
    "    [\"mnist_8x8\", mnist_8x8_train.shape[0], mnist_8x8_train.shape[1] * mnist_8x8_train.shape[2]],\n",
    "    [\"mnist_28x28\", mnist_28x28_train.shape[0], mnist_28x28_train.shape[1] * mnist_28x28_train.shape[2]]],\n",
    "    columns = [\"Dataset\", \"Size\", \"Features\"]\n",
    ")\n",
    "\n",
    "display(dataset_sizes)\n",
    "\n",
    "digit_count = np.zeros(20)\n",
    "\n",
    "for label in train_labels:\n",
    "    digit_count[label] += 1\n",
    "    \n",
    "digit_count = digit_count\n",
    "\n",
    "info = np.zeros(20).reshape(10, 2)\n",
    "\n",
    "for i in range(10):\n",
    "    info[i] = [i, digit_count[i]]\n",
    "    \n",
    "digits_frequency = pd.DataFrame(info, columns=[\"Digit\", \"Frequency\"])\n",
    "\n",
    "display(digits_frequency)\n",
    "\n",
    "print()\n",
    "\n",
    "i = 0\n",
    "print(\"Picture number {} in the train sets is of class: \".format(i), train_labels[i])\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(mnist_8x8_train[i], cmap='gray', vmin=0, vmax=255)\n",
    "axarr[1].imshow(mnist_28x28_train[i], cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "\"\"\"\n",
    "First images from the datasets are 1s. We can see the two images differ\n",
    "in the amount of information they provide because of the difference in dimensionality.\n",
    "\n",
    "The digits in the dataset are not uniformly distributed, because 0 is predominant, \n",
    "while 5 and 7 are least frequent.\n",
    "\n",
    "Because the data in the second dataset contains more correlation and more redundant information\n",
    "the resulting presumption is that the smaller dataset will on average perform better.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Components</th>\n",
       "      <th>Variance %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28x28</td>\n",
       "      <td>784</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28x28 PCA reduced</td>\n",
       "      <td>148</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8x8</td>\n",
       "      <td>64</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8x8 reduced</td>\n",
       "      <td>22</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset  Components  Variance %\n",
       "0              28x28         784       100.0\n",
       "1  28x28 PCA reduced         148        95.0\n",
       "2                8x8          64       100.0\n",
       "3        8x8 reduced          22        95.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Pre-processing\n",
    "\"\"\"\n",
    "Because we want every sample to be a feature vector in order to work with the\n",
    "classifiers, we will reshape the data in both datasets.\n",
    "\n",
    "No data cleaning is needed, because the dataset does not contain missing or null values.\n",
    "However, there is lots of redundant data and to get rid of it, we will perform PCA\n",
    "dimensionlaty reduction. In this way, we also significantly decrease the training time\n",
    "of algorithms like SVM and Decision Tree. \n",
    "\n",
    "The data has feature scaling and so there is little need to normalize the data for \n",
    "K-Nearest Neighbours, Logistic Regression or SVM. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Reshape the data\n",
    "mnist_28 = mnist_28x28_train.reshape(mnist_28x28_train.shape[0], 28 * 28)\n",
    "mnist_8 = mnist_8x8_train.reshape(mnist_8x8_train.shape[0], 8 * 8)\n",
    "\n",
    "# Dimensionality Reduction with PCA\n",
    "pca_8 = PCA(0.95)\n",
    "pca_28 = PCA(0.95)\n",
    "\n",
    "# Reduce 8x8\n",
    "mnist_8_reduced = pca_8.fit_transform(mnist_8)\n",
    "\n",
    "# Reduce 28x28\n",
    "mnist_28_reduced =  pca_28.fit_transform(mnist_28)\n",
    "\n",
    "dict = {\n",
    "    \"Dataset\": [\"28x28\", \"28x28 PCA reduced\", \"8x8\", \"8x8 reduced\"],\n",
    "    \"Components\": [28*28, mnist_28_reduced.shape[1], 8*8, mnist_8_reduced.shape[1]],\n",
    "    \"Variance %\": [100, pca_28.n_components * 100, 100, pca_8.n_components * 100]\n",
    "}\n",
    "comp = pd.DataFrame(dict)\n",
    "display(comp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWe will divide the train set into two, leaving 30% of the data as out validation set. We\\nwill also use a standard 5-fold cross-validation to get an average estimate of our classifiers'\\nperformance. In this way, we also ensure that the whole dataset will be used for testing, leading\\nto more correct classifier evaluation.\\n\\nHowever, we will not do it now because sklearn already provides a method for performing\\ncross-validation on a given dataset and labels.\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Experiments\n",
    "\"\"\"\n",
    "We will divide the train set into two, leaving 30% of the data as out validation set. We\n",
    "will also use a standard 5-fold cross-validation to get an average estimate of our classifiers'\n",
    "performance. In this way, we also ensure that the whole dataset will be used for testing, leading\n",
    "to more correct classifier evaluation.\n",
    "\n",
    "However, we will not do it now because sklearn already provides a method for performing\n",
    "cross-validation on a given dataset and labels.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB : 8x8:  0.8479999999999999, 28x28:  0.8397333333333334\n",
      "DecisionTreeClassifier : 8x8:  0.748, 28x28:  0.7128\n",
      "SVC : 8x8:  0.9389333333333333, 28x28:  0.9551999999999999\n",
      "KNeighbours : 8x8:  0.9256, 28x28:  0.9293333333333333\n",
      "LogisticRegression : "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8x8:  0.8797333333333335, 28x28:  0.8170666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe bar plot below shows the average accuracy of the five algorithms cross-validated\\nusing 90% train data and 10% validation data.\\nAs we can see, the performance is from worse to best:\\nDecision Tree < Naive Bayes < Logistic Regression < K-Nearest Neighbours < SVC\\n\\nThe plot also shows that on average:\\n    SVC and K-NN perform better with the larger dataset\\n    GaussianNB, Decision Tree and Logistic Regression perform better with the compressed dataset. \\n\\nExplanation of results is as follows:\\n1) Decision tree does not perform well because classes are not uniformly distributed.\\n2) The Naive Bayes also does not perform well as its assumtion of feature independence is incorrect.\\n3) Even after PCA, there is noise in the data, leading to lack of good convergence\\n    for gradient ascent of Logistic Regression.\\n\\n4) K-NN and SVC usually perform well with large datasets and weighted K-NN considers the distances to \\n    neighbours as well, making it less affected by the non-uniform digit distribution.\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will fit the models using\n",
    "\n",
    "scores_8x8 = np.zeros(5) \n",
    "scores_28x28 = np.zeros(5)\n",
    "\n",
    "index = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(\"{n} : \".format(n=name), end='')\n",
    "   \n",
    "    scores_8x8[index] = np.mean(cross_validate(model, mnist_8_reduced, train_labels, cv=10)['test_score'])\n",
    "    scores_28x28[index] = np.mean(cross_validate(model, mnist_28_reduced, train_labels, cv=10)['test_score'])\n",
    "    \n",
    "    print(\"8x8: \", scores_8x8[index], end=', ')\n",
    "    print(\"28x28: \", scores_28x28[index])\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "normal_scores_8x8 = scores_8x8    \n",
    "plot_results([scores_8x8, scores_28x28], \"Dataset 8x8\", \"Dataset 28x28\")\n",
    "\n",
    "'''\n",
    "The bar plot below shows the average accuracy of the five algorithms cross-validated\n",
    "using 90% train data and 10% validation data.\n",
    "As we can see, the performance is from worse to best:\n",
    "Decision Tree < Naive Bayes < Logistic Regression < K-Nearest Neighbours < SVC\n",
    "\n",
    "The plot also shows that on average:\n",
    "    SVC and K-NN perform better with the larger dataset\n",
    "    GaussianNB, Decision Tree and Logistic Regression perform better with the compressed dataset. \n",
    "\n",
    "Explanation of results is as follows:\n",
    "1) Decision tree does not perform well because classes are not uniformly distributed.\n",
    "2) The Naive Bayes also does not perform well as its assumtion of feature independence is incorrect.\n",
    "3) Even after PCA, there is noise in the data, leading to lack of good convergence\n",
    "    for gradient ascent of Logistic Regression.\n",
    "\n",
    "4) K-NN and SVC usually perform well with large datasets and in this case weighted K-NN considers the distances to \n",
    "    neighbours as well, making it less affected by the non-uniform digit distribution.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Logistic Regression\n",
    "param_grid_lr = { \n",
    "    'C': [0.01, 0.1, 1, 5, 10, 30],\n",
    "    'penalty': ['none', 'l1', 'l2', 'elasticnet']\n",
    "    }\n",
    "\n",
    "\n",
    "# SVC\n",
    "param_grid_svc = { \n",
    "    'C': [96, ],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "    \n",
    "# Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [ 10, 12, 14, 15, None],\n",
    "    'min_samples_leaf': np.linspace(0.000001, 0.00001 , 30, endpoint=True)\n",
    "}\n",
    "\n",
    "# K-Nearest Neighbours\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 4, 5, 6, 7, 10, 50, 70, 100],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "tuned_models['LogisticRegression'] = GridSearchCV(LogisticRegression(), param_grid_lr, refit=True, verbose=0)\n",
    "tuned_models['SVC'] = GridSearchCV(SVC(), param_grid_svc, refit=True, verbose=0)\n",
    "tuned_models['DecisionTreeClassifier'] = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, refit=True, verbose=0)\n",
    "tuned_models['KNeighbours'] = GridSearchCV(KNeighborsClassifier(), param_grid_knn, refit=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier :\n",
      "DecisionTreeClassifier(max_depth=15, min_samples_leaf=1.6206896551724138e-06)\n",
      "Split 0:  0.752\n",
      "DecisionTreeClassifier(max_depth=15, min_samples_leaf=6.5862068965517236e-06)\n",
      "Split 1:  0.7296\n",
      "DecisionTreeClassifier(max_depth=14, min_samples_leaf=8.758620689655173e-06)\n",
      "Split 2:  0.7728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyper-Parameter Tuning\n",
    "\n",
    "index = -1\n",
    "\n",
    "# Create a data splitter for the outer CV\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    \n",
    "    # Update index of the score to update\n",
    "    index += 1\n",
    "    \n",
    "    # Skip Naive Bayes\n",
    "    if name == \"GaussianNB\":\n",
    "        tuned_scores_8x8[index] = normal_scores_8x8[0]\n",
    "        continue\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    print(name, \":\")\n",
    "    cv_outer = StratifiedKFold(n_splits=6)\n",
    "    splits = cv_outer.split(mnist_8_reduced, train_labels)\n",
    "\n",
    "\n",
    "    for i, split in enumerate(splits):\n",
    "\n",
    "        # Get the splitted training and testing set\n",
    "        train_i, test_i = split[0], split[1]\n",
    "        trainX, testX, trainY, testY = (mnist_8_reduced[train_i], mnist_8_reduced[test_i], train_labels[train_i], train_labels[test_i])\n",
    "            \n",
    "        # Fit the model -> Get best hyper params in the inner CV\n",
    "        model.fit(trainX, trainY)\n",
    "        est = model.best_estimator_\n",
    "        print(est)\n",
    "                    \n",
    "        # Test it using the testing set in the outer CV\n",
    "        predictions = est.predict(testX)\n",
    "            \n",
    "        # Check whether it has the best performnce by now\n",
    "        score = accuracy_score(testY, predictions)\n",
    "        if score > best_score:\n",
    "                    \n",
    "            best_score = score\n",
    "            best_model = est\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Update the best params for the model\n",
    "            \n",
    "            \n",
    "        print(\"Split {i}: \".format(i=i), score)\n",
    "        \n",
    "    tuned_models[name] = best_model\n",
    "    print(tuned_models[name])\n",
    "    tuned_scores_8x8[index] = best_score\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To perform hyper-parameter tuning, we use double cross validation. To do this, we use\n",
    "a StratifiedKFold object to make 5 splits of our training mnist dataset into training and validation set.\n",
    "We use a GridSearchCV object to perform the inner cross validation. For every model and every \n",
    "split of the data, we fit the split's train data into the GridSearchCV object, which automatically performs the inner\n",
    "cross validation for every combination of the provided values for the model's hyper-parameters.\n",
    "The best performing combinations for every split are then compared in the outer CV with the split's validation set.\n",
    "\n",
    "The best perforing combination in the outer CV is used to tune the model.\n",
    "\n",
    "We perform this for both the large and the compressed mnist training datasets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for model in tuned_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GaussianNB': GaussianNB(), 'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=14, min_samples_leaf=9.068965517241379e-06), 'SVC': SVC(C=96), 'KNeighbours': KNeighborsClassifier(n_neighbors=4, weights='distance'), 'LogisticRegression': LogisticRegression(C=0.01)}\n",
      "GaussianNB\n",
      "DecisionTreeClassifier\n",
      "SVC\n",
      "KNeighbours\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dimitar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nAfter we tuned our models, we will compare their performance with that of the baseline versions by again performing\\na 10-fold cross validation. On the plot below we can see the results of testing our algorithms on the smaller PCA-reduced \\ndataset with and without hyper-parameter tuning. \\n\\nClearly only the K-NN and SVC classifiers managed to be improved in the process. For SVC, this \\nwas done by just decreasing the regularization parameter, thus reducing the amount of overfitting.\\nFor Nearest Neighbours, we again use the weighted k-nn version of the algorithm, but now with a smaller\\nnumber of neighbours to use for prediction. \\n\\nFor the other 2 tuned algorithms - Logistic Regression and Decision Tree, it could be that the method or comparison\\nmetric for tuning was not efficient enough, leading to a badly chosen combination of parameters.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the performance of the 8x8 dataset models / tuned_models\n",
    "\n",
    "perf_normal = normal_scores_8x8\n",
    "perf_tuned = np.zeros(5)\n",
    "\n",
    "index = 0\n",
    "\n",
    "print(tuned_models)\n",
    "\n",
    "for name, tuned_model in tuned_models.items():\n",
    "    print(name)\n",
    "    if name == \"GaussianNB\":\n",
    "        perf_tuned[index] = normal_scores_8x8[index]\n",
    "        index += 1\n",
    "        continue\n",
    "    perf_tuned[index] = np.mean(cross_validate(tuned_model, mnist_8_reduced, train_labels, cv=10)['test_score'])\n",
    "    index += 1                  \n",
    "                                \n",
    "plot_results([scores_8x8, perf_tuned], \"Baseline\", \"Tuned\")\n",
    "                                \n",
    "# Effect of tuning - results and differences\n",
    "\"\"\"\n",
    "After we tuned our models, we will compare their performance with that of the baseline versions by again performing\n",
    "a 10-fold cross validation. On the plot below we can see the results of testing our algorithms on the smaller PCA-reduced \n",
    "dataset with and without hyper-parameter tuning. \n",
    "\n",
    "Clearly only the K-NN and SVC classifiers managed to be improved in the process. For SVC, this \n",
    "was done by just decreasing the regularization parameter, thus reducing the amount of overfitting.\n",
    "For Nearest Neighbours, we again use the weighted k-nn version of the algorithm, but now with a smaller\n",
    "number of neighbours to use for prediction. \n",
    "\n",
    "For the other 2 tuned algorithms - Logistic Regression and Decision Tree, it could be that the method or comparison\n",
    "metric for tuning was not efficient enough, leading to a badly chosen combination of parameters.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c0afca90ff2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Comparison of performance with the different number of features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores_8x8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_28x28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Dataset 8x8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Dataset 28x28\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Comparison of performance with the different number of features\n",
    "\n",
    "plot_results([scores_8x8, scores_28x28], \"Dataset 8x8\", \"Dataset 28x28\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The results by now showed 3 of the 5 algorithms perform worse with the larger dataset,\n",
    "which corresponds with the initial assumption.\n",
    "\n",
    "Presumably, Decision Tree and Logistic Regression are affected by the general curse of dimensionality problem,\n",
    "while the Naive Bayes is affected by the increase of feature correlation and noise in the data.\n",
    "\n",
    "SVC and K-NN are not affected by the curse of dimensionality in this case, probably because of \n",
    "the large training set size and the right parameters.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 0 0 5 7 9 0 6 6 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pre-process data of the test 28x28 set\n",
    "mnist_8x8_test_reshaped = mnist_8x8_test.reshape(mnist_8x8_test.shape[0], 64)\n",
    "\n",
    "test_dataset = pca_8.transform(mnist_8x8_test_reshaped)\n",
    "\n",
    "best_algorithm = SVC(C=10)\n",
    "\n",
    "\n",
    "best_algorithm.fit(mnist_8_reduced, train_labels)\n",
    "\n",
    "prediction = best_algorithm.predict(test_dataset)\n",
    "\n",
    "print(prediction[1240:1250])\n",
    "\n",
    "f, axarr = plt.subplots(1,10)\n",
    "for i in range(10):\n",
    "    axarr[i].imshow(mnist_28x28_test[1240+i], cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    \n",
    "    \n",
    "# pd.DataFrame(prediction).to_csv(\"GROUP_classes_problem_mnist.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
